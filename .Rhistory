p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
else wgt <- rep(1,N)
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
# Rank and Cluster Binomial Data CT Example
#setwd("/Users/cora/git_repos/ClusteredRanking/")
#binData <- read.csv("data/alcohol_ct.csv")
#devtools::use_data(binData, overwrite = TRUE)
require(dplyr)
require(reshape2)
require(clue)
require(Hmisc)
require(RColorBrewer)
#setwd("/Users/cora/git_repos/ClusteredRanking/") #Need this?
load(file = "data/binData.rda")
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
lbw_rc$theta
lbw_rc_unweight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=FALSE)
lbw_rc_unweight$theta
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county, weighted=TRUE)
lbw_rc$theta
# rank scale
lbw_rc_rnk <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,scale=rank)
lbw_rc_rnk$theta
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
setwd("/Users/cora/git_repos/ClusteredRanking/")
normData <- read.csv("data/normal_ct.csv")
devtools::use_data(normData, overwrite = TRUE)
poisData <- read.csv("data/lbw_ct.csv")
devtools::use_data(poisData, overwrite = TRUE)
devtools::test()
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
print(wgt)
}
#functions for grouped ranking
#use this instead? devtools::use_package("dplyr") # Defaults to imports
library(ggplot2)
library(reshape2)
library(clue)
library(Hmisc)
library(RColorBrewer)
#TODO binomial data should be something else. use LBW for poisson
npmle.bin <- function(y,n,k=NULL,n.iter=1000,row_names=NULL) {
#k is number of initial clusters
if (is.null(k)) {
theta<-sort(y/n) #sorted probabilities
k<-length(theta) #k = number of units to rank
} else {
theta <- seq(min(y/n),max(y/n),length=k) #starting mass points of F. We're estimating these, along with p_theta
}
p_theta <- rep(1/k,k) #probabilities of each mass point.
E_z <- matrix(NA,length(y),k) #expected value of the probability that you're in each of the k theta groups
#calculating the p that z_{ij} is equal to theta star j
for (j in 1:n.iter) {
for (i in 1:k) {
#numerator
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes (pseudo zs). This is the E part of EM alg
p_theta <- apply(E_z,2,mean) #M-step: means over the matrix
theta <- y%*%E_z/n%*%E_z #calculates optimal theta for each group
}
#this reduces down to needed number of groups (<=k)
ord<-order(theta)
theta<-c(theta[ord]) #sorts
p_theta<-p_theta[ord] #sorts
p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
print(wgt)
}
else {
wgt <- rep(1,N)
}
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
weight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=TRUE)
unweight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=FALSE)
weight$ranked_table
weight$ranked_table$name
unweight$ranked_table$name
as.vector(unweight$ranked_table$name)
devtools::test()
devtools::test()
#functions for grouped ranking
#use this instead? devtools::use_package("dplyr") # Defaults to imports
library(ggplot2)
library(reshape2)
library(clue)
library(Hmisc)
library(RColorBrewer)
#TODO binomial data should be something else. use LBW for poisson
npmle.bin <- function(y,n,k=NULL,n.iter=1000,row_names=NULL) {
#k is number of initial clusters
if (is.null(k)) {
theta<-sort(y/n) #sorted probabilities
k<-length(theta) #k = number of units to rank
} else {
theta <- seq(min(y/n),max(y/n),length=k) #starting mass points of F. We're estimating these, along with p_theta
}
p_theta <- rep(1/k,k) #probabilities of each mass point.
E_z <- matrix(NA,length(y),k) #expected value of the probability that you're in each of the k theta groups
#calculating the p that z_{ij} is equal to theta star j
for (j in 1:n.iter) {
for (i in 1:k) {
#numerator
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes (pseudo zs). This is the E part of EM alg
p_theta <- apply(E_z,2,mean) #M-step: means over the matrix
theta <- y%*%E_z/n%*%E_z #calculates optimal theta for each group
}
#this reduces down to needed number of groups (<=k)
ord<-order(theta)
theta<-c(theta[ord]) #sorts
p_theta<-p_theta[ord] #sorts
p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
}
else {
wgt <- rep(1,N)
}
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
devtools::test()
devtools::test()
typeof(unweight$ranked_table$name)
unweight$ranked_table$name
as.vector(unweight$ranked_table$name)
as.vector(unweight$ranked_table$name) == c("Middlesex", "Litchfield", "Tolland", "Windham", "New London", "Fairfield", "New Haven", "Hartford")
devtools::test()
as.vector(weight$ranked_table$name) == c("Middlesex", "Litchfield", "Tolland", "Windham", "New London", "Fairfield", "New Haven", "Hartford")
devtools::test()
unweight$ranked_table$name
weight$ranked_table$name
devtools::test()
library(ClusterRanking)
library(ClusteredRanking)
library(ClusteredRanking)
library(ClusteredRanking)
library(ClusteredRanking)
devtools::test()
devtools::test()
binomial
typeof(binomial)
devtools::test()
devtools::test()
devtools::test()
Hmisc::binconf(y,n)
Hmisc::binconf(binData$lbw,binData$births)
binconf <- Hmisc::binconf(binData$lbw,binData$births)
typeof(binconf)
dim(binconf)
str(binconf)
poisconf <- matrix(ncol = 3, nrow = n)
poisconf <- matrix(ncol = 3)
poisconf
poisconf <- matrix(ncol = 3, nrow = 10)
poisconf
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = c("PointEst", "Lower", "Upper")
)
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = c("PointEst", "Lower", "Upper"))
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper")))
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),NULL))
colnames(poisconf) = c("PointEst", "Lower", "Upper")
poisconf
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),rep("", n)))
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),rep("", 10)))
rep("", 10)
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),c(rep("", 10))))
length(list(c("PointEst", "Lower", "Upper"),c(rep("", 10))))
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),c(rep("", 10))))
poisconf <- matrix(ncol = 3, nrow = 10, dimnames = list(c("PointEst", "Lower", "Upper"),c(rep("", 10))))
rownames(poisconf) = c(rep("", 10))
poisconf
poisconf[,"PointEst"]
poisson.test(42, conf.level = 0.9 )
poisson.test(42, conf.level = 0.95)
exactPoiCI(42, 0.99)
exactPoiCI <- function (X, conf.level=0.95) {
alpha = 1 - conf.level
upper <- 0.5 * qchisq(1-alpha/2, 2*X+2)
lower <- 0.5 * qchisq(alpha/2, 2*X)
return(c(lower, upper))
}
exactPoiCI(42, 0.9)
poisson.test(42, conf.level = 0.9)
p1 <- poisson.test(42, conf.level = 0.9)
p1$parameter
p1$estimate
as.integer(p1$estimate)
p1$conf.int
p1$conf.int[1]
library(ClusteredRanking)
unweight <- ClusterRank(binData$lbw,binData$births,datatype="binomial",row_names=binData$county,weighted=FALSE)
as.vector(unweight$ranked_table$name)
unweight <- ClusterRank(binData$lbw,binData$births,datatype="binomial",row_names=binData$county,weighted=FALSE)
library(ClusteredRanking)
unweight <- ClusterRank(binData$lbw,binData$births,datatype="binomial",row_names=binData$county,weighted=FALSE)
library(ClusteredRanking)
unweight <- ClusterRank(binData$lbw,binData$births,datatype="binomial",row_names=binData$county,weighted=FALSE)
as.vector(unweight$ranked_table$name)
devtools::test()
weight <- ClusterRank(binData$lbw,binData$births,datatype="binomial",row_names=binData$county,weighted=TRUE)
as.vector(weight$ranked_table$name)
devtools::test()
View(poisData)
poisData$county
devtools::test()
devtools::test()
library(ClusteredRanking)
library(ClusteredRanking)
devtools::test()
devtools::test()
library(ClusteredRanking)
library(ClusteredRanking)
devtools::test()
devtools::test()
library(ClusteredRanking)
devtools::test()
pwd
getwd()
load(file = "data/binData.rda")
library(ClusteredRanking)
devtools::test()
devtools::test()
library(ClusteredRanking)
devtools::test()
exactPoiCI <- function (X, conf.level=0.95) {
alpha = 1 - conf.level
upper <- 0.5 * qchisq(1-alpha/2, 2*X+2)
lower <- 0.5 * qchisq(alpha/2, 2*X)
return(c(lower, upper))
}
exactPoiCI(c(3,4,5), conf.level=.95)
library(ClusteredRanking)
devtools::test()
ClusterRank(poisData$lbw, poisData$births, datatype = "poisson", row_names = poisData$county,
weighted = FALSE)
library(ClusteredRanking)
devtools::test()
unweight <- ClusterRank(poisData$lbw,poisData$births,datatype = "poisson", row_names=poisData$county,weighted=FALSE)
unweight$theta
View(poisData)
unweight <- ClusterRank(poisData$lbw,datatype = "poisson", row_names=poisData$county,weighted=FALSE)
weight <- ClusterRank(poisData$lbw,datatype = "poisson", row_names=poisData$county,weighted=TRUE)
weight <- ClusterRank(poisData$lbw,poisData$births,datatype = "poisson", row_names=poisData$county,weighted=TRUE)
weight$theta
unweight$ranked_table$name
library(ClusteredRanking)
devtools::test()
ClusterRank(normData$lbw,normData$births,datatype = "normal",row_names=normData$county,weighted=FALSE)
load(normData)
load(file = "normData.rda")
load(file = "data/normData.rda")
devtools::test()
View(normData)
library(ClusteredRanking)
devtools::test()
ClusterRank(normData$lbw, normData$births, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
ClusterRank(normData$lbw, normData$births, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
ClusterRank(normData$lbw, normData$births, datatype = "normal", row_names = normData$county,
weighted = FALSE)
round(c(5.1, 5.2))
View(normData)
View(normData)
library(ClusteredRanking)
ClusterRank(normData$lbw, normData$births, datatype = "normal", row_names = normData$county,
weighted = FALSE)
ClusterRank(normData$mean, se=normData$se, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
ClusterRank(normData$mean, se=normData$se, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
weighted = FALSE)
ClusterRank(normData$mean, se=normData$se, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
devtools::test()
ClusterRank(normData$mean, se=normData$se, datatype = "normal", row_names = normData$county,
weighted = FALSE)
library(ClusteredRanking)
View(normData)
seq(2.9, 3.5)
seq(2.9, 3.5, length = 5)
library(ClusteredRanking)
devtools::test()
