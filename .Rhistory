}
}
rnk <- as.numeric(solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$lambda))[rnk]
grp <- factor(grp)
p_grp <- npmle_res$post_lambda[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$lambda,3)
ord <- order(rnk)
CI <- poisconf(y,n)
ranked_table <- data_frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_lambda%*%npmle_res$lambda),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_lambda[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,lambda=npmle_res$lambda,pr_lambda=npmle_res$p_lambda))
}
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
geom_point(pch=3)+
geom_point(aes(x=pm),pch=4)+
geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
scale_x_continuous(xlab,breaks=rc$lambda[!duplicated(round(rc$lambda,2))],
labels=round(rc$lambda[!duplicated(round(rc$lambda,2))],3),minor_breaks=rc$lambda)+
scale_color_manual(values=rep(brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
scale_size_area(max_size=5)+
scale_alpha(limits=c(0,1),range=c(0,1))+
theme_bw()+
guides(color=FALSE,size=FALSE,alpha=FALSE))
}
poisData <- read_csv("data/lbw_ct.csv")
poisData <- poisData %>% mutate(nbw=births-lbw) %>% filter(!is.na(lbw))
lbw_rc <- rank_cluster.pois(poisData$lbw,poisData$births,row_names=poisData$county)
View(poisData)
poisData$county
poisData <- poisData %>% mutate(nbw=births-lbw) %>% filter(!is.na(lbw))
lbw_rc <- rank_cluster.pois(poisData$lbw,poisData$births,row_names=poisData$county)
lambda <- seq(min(poisData$y/poisData$n),max(poisData$y/poisData$n),length=8)
lambda <- seq(min(poisData$lbw/poisData$births),max(poisData$lbw/poisData$births),length=8)
p_lambda <- rep(1/8,8)
E_z <- matrix(NA,length(poisData$births),8)
for (j in 1:1000) {
for (i in 1:8) {
#The R function dpois(x, lambda) calculates the probability that there are x events in an interval,
#where the argument "lambda" is the average number of events per interval.
#TODO check this In dpois(y/n, lambda[i], log = TRUE) : non-integer x = 0.076169
#this is the mixture distribution, right?
E_z[,i] <- log(p_lambda[i])+dpois(poisData$births, lambda[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #E_z will be
p_lambda <- apply(E_z,2,mean)
lambda <- poisData$lbw%*%E_z/n%*%E_z #does this reassign lambda? Do we want this?
}
for (j in 1:1000) {
for (i in 1:8) {
#The R function dpois(x, lambda) calculates the probability that there are x events in an interval,
#where the argument "lambda" is the average number of events per interval.
#TODO check this In dpois(y/n, lambda[i], log = TRUE) : non-integer x = 0.076169
#this is the mixture distribution, right?
E_z[,i] <- log(p_lambda[i])+dpois(poisData$births, lambda[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #E_z will be
p_lambda <- apply(E_z,2,mean)
lambda <- poisData$lbw%*%E_z/poisData$births%*%E_z #does this reassign lambda? Do we want this?
}
ord<-order(lambda)
lambda<-c(lambda[ord])
p_lambda<-p_lambda[ord]
p_lambda <- tapply(p_lambda,cumsum(!duplicated(round(lambda,8))),sum)
lambda <- lambda[!duplicated(round(lambda,8))]
E_z <- matrix(NA,length(poisData$lbw),length(lambda))
for (i in 1:length(lambda)) {
E_z[,i] <- log(p_lambda[i])+dpois(poisData$lbw/poisData$births,lambda[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x)))))
rownames(E_z)<-row_names
rn <- poisData$county
rownames(E_z)<-rn
dim(E_z)
length(rn)
rownames(t(E_z)) <- rn
rownames(t(E_z)) <- rn
t(E_z)
E_z <- matrix(NA,8,length(lambda))
for (i in 1:length(lambda)) {
E_z[,i] <- log(p_lambda[i])+dpois(poisData$lbw,lambda[i],log=TRUE)
}
E_z
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x)))))
log(p_lambda[i])+dpois(poisData$lbw,lambda[i],log=TRUE)
dpois(poisData$lbw,lambda[i],log=TRUE)
log(p_lambda[i])
p_lambda
ord
lambda<-c(lambda[ord])
lambda
View(binData)
#setwd("/Users/cora/git_repos/ClusteredRanking/") #Need this?
load(file = "data/binData.rda")
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
#setwd("/Users/cora/git_repos/ClusteredRanking/") #Need this?
load(file = "data/binData.rda")
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
#functions for grouped ranking
#use this instead? devtools::use_package("dplyr") # Defaults to imports
library(ggplot2)
library(reshape2)
library(clue)
library(Hmisc)
library(RColorBrewer)
#TODO binomial data should be something else. use LBW for poisson
npmle.bin <- function(y,n,k=NULL,n.iter=1000,row_names=NULL) {
#k is number of initial clusters
if (is.null(k)) {
theta<-sort(y/n) #sorted probabilities
k<-length(theta) #k = number of units to rank
} else {
theta <- seq(min(y/n),max(y/n),length=k) #starting mass points of F. We're estimating these, along with p_theta
}
p_theta <- rep(1/k,k) #probabilities of each mass point.
E_z <- matrix(NA,length(y),k) #expeted value of the probability that you're in each of the k theta groups
#calculating the p that z_{ij} is equal to theta star j
for (j in 1:n.iter) {
for (i in 1:k) {
#numerator
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes (pseudo zs). This is the E part of EM alg
p_theta <- apply(E_z,2,mean) #M-step: means over the matrix
theta <- y%*%E_z/n%*%E_z #calculates optimal theta for each group
}
#this reduces down to needed number of groups k
ord<-order(theta)
theta<-c(theta[ord]) #sorts
p_theta<-p_theta[ord] #sorts
p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
else wgt <- rep(1,N)
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
# Rank and Cluster Binomial Data CT Example
#setwd("/Users/cora/git_repos/ClusteredRanking/")
#binData <- read.csv("data/alcohol_ct.csv")
#devtools::use_data(binData, overwrite = TRUE)
require(dplyr)
require(reshape2)
require(clue)
require(Hmisc)
require(RColorBrewer)
#setwd("/Users/cora/git_repos/ClusteredRanking/") #Need this?
load(file = "data/binData.rda")
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county)
lbw_rc$theta
lbw_rc_unweight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=FALSE)
lbw_rc_unweight$theta
lbw_rc <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county, weighted=TRUE)
lbw_rc$theta
# rank scale
lbw_rc_rnk <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,scale=rank)
lbw_rc_rnk$theta
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
devtools::test()
setwd("/Users/cora/git_repos/ClusteredRanking/")
normData <- read.csv("data/normal_ct.csv")
devtools::use_data(normData, overwrite = TRUE)
poisData <- read.csv("data/lbw_ct.csv")
devtools::use_data(poisData, overwrite = TRUE)
devtools::test()
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
print(wgt)
}
#functions for grouped ranking
#use this instead? devtools::use_package("dplyr") # Defaults to imports
library(ggplot2)
library(reshape2)
library(clue)
library(Hmisc)
library(RColorBrewer)
#TODO binomial data should be something else. use LBW for poisson
npmle.bin <- function(y,n,k=NULL,n.iter=1000,row_names=NULL) {
#k is number of initial clusters
if (is.null(k)) {
theta<-sort(y/n) #sorted probabilities
k<-length(theta) #k = number of units to rank
} else {
theta <- seq(min(y/n),max(y/n),length=k) #starting mass points of F. We're estimating these, along with p_theta
}
p_theta <- rep(1/k,k) #probabilities of each mass point.
E_z <- matrix(NA,length(y),k) #expected value of the probability that you're in each of the k theta groups
#calculating the p that z_{ij} is equal to theta star j
for (j in 1:n.iter) {
for (i in 1:k) {
#numerator
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes (pseudo zs). This is the E part of EM alg
p_theta <- apply(E_z,2,mean) #M-step: means over the matrix
theta <- y%*%E_z/n%*%E_z #calculates optimal theta for each group
}
#this reduces down to needed number of groups (<=k)
ord<-order(theta)
theta<-c(theta[ord]) #sorts
p_theta<-p_theta[ord] #sorts
p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
print(wgt)
}
else {
wgt <- rep(1,N)
}
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
weight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=TRUE)
unweight <- rank_cluster.bin(binData$lbw,binData$births,row_names=binData$county,weighted=FALSE)
weight$ranked_table
weight$ranked_table$name
unweight$ranked_table$name
as.vector(unweight$ranked_table$name)
devtools::test()
devtools::test()
#functions for grouped ranking
#use this instead? devtools::use_package("dplyr") # Defaults to imports
library(ggplot2)
library(reshape2)
library(clue)
library(Hmisc)
library(RColorBrewer)
#TODO binomial data should be something else. use LBW for poisson
npmle.bin <- function(y,n,k=NULL,n.iter=1000,row_names=NULL) {
#k is number of initial clusters
if (is.null(k)) {
theta<-sort(y/n) #sorted probabilities
k<-length(theta) #k = number of units to rank
} else {
theta <- seq(min(y/n),max(y/n),length=k) #starting mass points of F. We're estimating these, along with p_theta
}
p_theta <- rep(1/k,k) #probabilities of each mass point.
E_z <- matrix(NA,length(y),k) #expected value of the probability that you're in each of the k theta groups
#calculating the p that z_{ij} is equal to theta star j
for (j in 1:n.iter) {
for (i in 1:k) {
#numerator
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes (pseudo zs). This is the E part of EM alg
p_theta <- apply(E_z,2,mean) #M-step: means over the matrix
theta <- y%*%E_z/n%*%E_z #calculates optimal theta for each group
}
#this reduces down to needed number of groups (<=k)
ord<-order(theta)
theta<-c(theta[ord]) #sorts
p_theta<-p_theta[ord] #sorts
p_theta <- tapply(p_theta,cumsum(!duplicated(round(theta,8))),sum) #cumsum numbers groups is ascending order. sums the pthetas that goes with each group. See pictures
theta <- theta[!duplicated(round(theta,8))] #removes duplicate thetas
E_z <- matrix(NA,length(y),length(theta))
#final posterior probabilties for each county. Pr(county in group i)
for (i in 1:length(theta)) {
E_z[,i] <- log(p_theta[i])+dbinom(y,n,theta[i],log=TRUE)
}
E_z <- t(apply(E_z,1,function(x) exp(x-max(x))/sum(exp(x-max(x))))) #normalizes probabilities. subtracts max to avoid underflow
rownames(E_z)<-row_names
colnames(E_z)<-signif(theta,3) #group names are rounded
return(list(theta=theta, p_theta=p_theta, post_theta=E_z))
#return(prior for theta, prior for p_theta, posterior)
}
#TODO change all to theta to make this function universal
rank_cluster.bin <- function(y,n,k=NULL,scale=identity,weighted=TRUE,n.iter=1000,n.samp=10000,row_names=NULL) {
#assigns ranks then clusters to each item in a list for binomial data
N <- length(y)
npmle_res <- npmle.bin(y,n,k,n.iter,row_names)
smp <- apply(npmle_res$post_theta,1,
function(x,theta,n.samp)
sample(theta,n.samp,replace=TRUE,prob=x),
theta=scale(npmle_res$theta),n.samp=n.samp)
smp <- t(smp)
smp.ord <- apply(smp,2,sort)
if (weighted) { #inverse variance weighting
wgt <- 1/pmax(.Machine$double.eps,apply(smp,1,var)) #if variance is zero, uses v small value to weight,
#making it impossible to reassign a low variance estimate to new group
}
else {
wgt <- rep(1,N)
}
loss <- matrix(NA,N,N)
for (i in 1:N) {
for (j in 1:N) {
loss[i,j] <- wgt[i] * mean((smp[i,]-smp.ord[j,])^2)
}
}
rnk <- as.numeric(clue::solve_LSAP(loss))
grp <- match(apply(smp.ord,1,getmode),scale(npmle_res$theta))[rnk]
#matches rank positions to groups using mode. The mode version minimizes indicator (see pic)
#^ We could replace this with squared error diff. See pic. TODO
grp <- factor(grp)
p_grp <- npmle_res$post_theta[cbind(1:N,as.numeric(grp))]
levels(grp) <- signif(npmle_res$theta,3) #labels
ord <- order(rnk)
CI <- Hmisc::binconf(y,n) #creating confidence intervals (TODO for Pois, Normal)
ranked_table <- data.frame(name=row_names,rank=rnk,group=factor(grp),
y=y,n=n,p=y/n,
p_LCL=CI[,2],p_UCL=CI[,3],
pm=c(npmle_res$post_theta%*%npmle_res$theta),
p_grp=p_grp)
ranked_table <- ranked_table[ord,]
ranked_table$name <- factor(ranked_table$name,levels=ranked_table$name,ordered=TRUE)
posterior <- npmle_res$post_theta[ord,]
return(list(ranked_table=ranked_table,posterior=posterior,theta=npmle_res$theta,pr_theta=npmle_res$p_theta))
}
getmode <- function(v) {
#retrieves mode from list v
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
plot_rt <- function(rc,xlab="Proportion") {
post_df <- reshape2::melt(rc$posterior)
post_df$group <- rc$ranked_table$group[match(post_df$Var1,rc$ranked_table$name)]
post_df$p_grp <- rc$ranked_table$p_grp[match(post_df$Var1,rc$ranked_table$name)]
return(ggplot2::ggplot(rc$ranked_table,aes(y=name,x=p,color=group,alpha=p_grp))+
ggplot2::geom_point(pch=3)+
ggplot2::geom_point(aes(x=pm),pch=4)+
ggplot2::geom_point(data=post_df,aes(y=Var1,x=as.numeric(Var2),color=group,size=value,alpha=value))+
ggplot2::geom_errorbarh(aes(xmin=p_LCL,xmax=p_UCL),height=0)+
ggplot2::scale_y_discrete("",limits=rev(levels(rc$ranked_table$name)))+
ggplot2::scale_x_continuous(xlab,breaks=rc$theta[!duplicated(round(rc$theta,2))],
labels=round(rc$theta[!duplicated(round(rc$theta,2))],3),minor_breaks=rc$theta)+
ggplot2::scale_color_manual(values=rep(RColorBrewer::brewer.pal(8,"Dark2"),1+floor(length(levels(rc$ranked_table$group))/8)))+
ggplot2::scale_size_area(max_size=5)+
ggplot2::scale_alpha(limits=c(0,1),range=c(0,1))+
ggplot2::theme_bw()+
ggplot2::guides(color=FALSE,size=FALSE,alpha=FALSE))
}
devtools::test()
devtools::test()
typeof(unweight$ranked_table$name)
unweight$ranked_table$name
as.vector(unweight$ranked_table$name)
as.vector(unweight$ranked_table$name) == c("Middlesex", "Litchfield", "Tolland", "Windham", "New London", "Fairfield", "New Haven", "Hartford")
devtools::test()
as.vector(weight$ranked_table$name) == c("Middlesex", "Litchfield", "Tolland", "Windham", "New London", "Fairfield", "New Haven", "Hartford")
devtools::test()
unweight$ranked_table$name
weight$ranked_table$name
devtools::test()
library(ClusterRanking)
library(ClusteredRanking)
library(ClusteredRanking)
